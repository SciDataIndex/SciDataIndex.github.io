{
  "dataset": "ClimaQA",
  "intro": {
    "official_link": "https://huggingface.co/datasets/Rose-STL-Lab/ClimaQA",
    "brief_description": "ClimaQA 是一个用于评估气候科学问答模型的大型基准数据集，分为两部分：ClimaQA-Gold（专家标注）和 ClimaQA-Silver（自动生成）。数据集来源于研究生级别的气候科学教科书，涵盖多种问答形式和难度层级，旨在评估大语言模型在科学领域中的知识准确性和推理能力。",
    "detailed_description": "数据集简述：ClimaQA 是为了弥补当前通用 LLM 基准在科学问答领域，特别是气候科学中的不足。该数据集由自动生成和专家校验两个部分组成，设计用于挑战模型从基础知识回忆到复杂科学推理的能力。\n数据集内容：内容方面，数据集包含三种任务形式：选择题（MCQ）、自由回答（Freeform）和填空题（Cloze），并按照难度划分为基础类、推理类和假设类。所有题目均基于真实气候科学教材内容构建，确保其科学性与语义相关性。\n关键元信息：问题类型（MCQ、Freeform、Cloze）、难度分类、问题内容和答案，以及来源教材的上下文片段。这些元信息有助于细粒度分析模型在不同任务和复杂度下的表现。\n重要应用场景：科学问答系统评估、语言模型微调、检索增强生成（RAG）评测及科学语言理解研究，适用于模型开发者、气候学研究人员和教育者等多个领域。"
  },
  "openness": {
    "license_type": "Apache License 2.0",
    "license_source_link": "https://github.com/Rose-STL-Lab/genie-climaqa?tab=Apache-2.0-1-ov-file",
    "charging_mode": "完全免费",
    "access_restrictions": "全量下载",
    "application_difficulty": "无需申请"
  },
  "data_scale": {
    "data_volume": "1.3 MB",
    "data_volume_mb": "1.3",
    "source_of_data_volume": "https://huggingface.co/datasets/Rose-STL-Lab/ClimaQA",
    "estimated_manually": "否"
  },
  "impact": {
    "paper_link": "https://arxiv.org/abs/2410.16701",
    "paper_citations_raw": "2.0",
    "paper_citations": "2",
    "google_scholar_related_papers": "10.0",
    "google_scholar_screenshot": "image.png",
    "download_volume_or_user_count": "-",
    "models_using_this_dataset": "nan"
  },
  "safety": {
    "control_level": "不受管控",
    "traceability": "有元数据"
  },
  "AI_readiness": {
    "annotation_density": "有标注",
    "preprocessing_level": "已预经过处理",
    "format_consistency": "格式不统一"
  },
  "data_quality": {
    "integrity": "部分缺失",
    "first_release_date": "2025/02/10",
    "source_link": "https://huggingface.co/datasets/Rose-STL-Lab/ClimaQA/commits/main",
    "last_update_date": "2025/03/18"
  }
}
