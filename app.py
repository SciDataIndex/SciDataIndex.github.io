import json
import os
import time

import pandas as pd
from fastapi import FastAPI, Query
from fastapi.middleware.cors import CORSMiddleware
from starlette.responses import HTMLResponse, JSONResponse
from utils import *
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from rating2 import build_dataset_profile
import asyncio
from logger import *
app = FastAPI()

@app.get("/api/log-stream")
def log_stream_api(since: int = 0):
    # è¿”å›çš„æ˜¯ä¸€ä¸ª HTTP Responseï¼Œ
    # ä½†è¿™ä¸ª Response çš„ body æ˜¯â€œæµå¼çš„â€ï¼Œ
    # è€Œä¸æ˜¯ä¸€æ¬¡æ€§æ•°æ®ã€‚
    return StreamingResponse(log_stream(since), media_type="text/event-stream")


# è¯­ä¹‰å‘é‡ç›¸ä¼¼åº¦æ¨¡å‹é¢„çƒ­
model = SentenceTransformer("all-MiniLM-L6-v2")
# text1 = "æ°”å€™å˜åŒ–å¦‚ä½•å½±å“ä¸œäºšé™æ°´æ¨¡å¼"
# text2 = "ç ”ç©¶å…¨çƒå˜æš–å¯¹ä¸œäºšåœ°åŒºé™é›¨ç»“æ„çš„å½±å“"
# emb1 = model.encode([text1])
# emb2 = model.encode([text2])
# sim = cosine_similarity(emb1, emb2)[0][0]



# å…è®¸å‰ç«¯è®¿é—®ï¼ˆæœ¬åœ°å¼€å‘å¿…å¤‡ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç¤ºä¾‹æ•°æ®ï¼ˆä½ ä¹‹åå¯ä»¥æ¢æˆæ•°æ®åº“ï¼‰
DATASETS = {
    "åœ°çƒç§‘å­¦": [
        {
            "name": "Coupled Model Intercomparison Project",
            "desc": "è€¦åˆæ°”å€™æ¨¡å‹æ¯”è¾ƒé¡¹ç›®",
            "detail": "åŸºäºç¬¬ä¸€æ€§åŸç†è®¡ç®—ï¼Œæä¾›å¤§è§„æ¨¡ææ–™ç»“æ„ä¸èƒ½å¸¦æ€§è´¨æ•°æ®",
            "rating": {
                "openness": 8,
                "quality": 10,
                "scale": 10,
                "impact": 6,
                "safety": 10,
                "ai_readiness": 6,
                "total_score": 8.0
            }
        },
        {
            "name": "Hubble Space Telescope Data",
            "desc": "å“ˆå‹ƒå¤ªç©ºæœ›è¿œé•œå›¾åƒè§‚æµ‹æ•°æ®",
            "detail": "ç”¨äºç ”ç©¶å‚¬åŒ–ååº”è·¯å¾„ã€å¸é™„èƒ½ä¸ååº”èƒ½å’çš„é«˜è´¨é‡æ•°æ®é›†",
            "rating": {
                "openness": 8,
                "quality": 10,
                "scale": 8,
                "impact": 6,
                "safety": 10,
                "ai_readiness": 6,
                "total_score": 7.4
            }
        },
        {
            "name": "ECMWF reanalysis",
            "desc": "æ¬§æ´²æ°”è±¡ä¸­å¿ƒå…¨çƒæ°”è±¡å†åˆ†æèµ„æ–™",
            "detail": "åŒ…å« 13 ä¸‡ä½™ç§å°åˆ†å­çš„é‡å­åŒ–å­¦æ€§è´¨è®¡ç®—ç»“æœ",
            "rating": {
                "openness": 8,
                "quality": 10,
                "scale": 8,
                "impact": 0,
                "safety": 7,
                "ai_readiness": 7,
                "total_score": 5.95
            }
        },
{
            "name": "Sloan Digital Sky Survey",
            "desc": "æ–¯éš†æ•°å­—å¤©ç©ºå·¡å¤©",
            "detail": "åŒ…å« 13 ä¸‡ä½™ç§å°åˆ†å­çš„é‡å­åŒ–å­¦æ€§è´¨è®¡ç®—ç»“æœ",
            "rating": {
                "openness": 8,
                "quality": 9,
                "scale": 8,
                "impact": 6,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 7.15
            }
        },
{
            "name": "Event Horizon Telescope Observations",
            "desc": "äº‹ä»¶è§†ç•Œæœ›è¿œé•œè§‚æµ‹æ•°æ®",
            "detail": "åŒ…å« 13 ä¸‡ä½™ç§å°åˆ†å­çš„é‡å­åŒ–å­¦æ€§è´¨è®¡ç®—ç»“æœ",
            "rating": {
                "openness": 10,
                "quality": 0,
                "scale": 9,
                "impact": 6,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 6.75
            }
        }
    ],

    "ç¥ç»ç§‘å­¦": [
        {
            "name": "Hemibrain Connectome Dataset",
            "desc": "æœè‡åŠè„‘è¿æ¥ç»„å›¾è°±",
            "detail": "é«˜åˆ†è¾¨ç‡äººç±»è„‘ç»“æ„ä¸åŠŸèƒ½è¿æ¥æ•°æ®",
            "rating": {
                "openness": 8,
                "quality": 9,
                "scale": 7,
                "impact": 2,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 5.85
            }
        },
        {
            "name": "HMC Sleep Staging Dataset",
            "desc": "äº”åˆ†ç±»ç¡çœ åˆ†æœŸè„‘ç”µæ•°æ®é›†",
            "detail": "æä¾›å¤šå°ºåº¦è„‘åŒºåŸºå› è¡¨è¾¾ä¸è§£å‰–ç»“æ„ä¿¡æ¯",
            "rating": {
                "openness": 8,
                "quality": 9,
                "scale": 4,
                "impact": 4,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 5.45
            }
        },
        {
            "name": "BOLD5000",
            "desc": "ä¸€ä¸ªå¤§è§„æ¨¡ã€æ…¢é€Ÿäº‹ä»¶ç›¸å…³çš„fMRIæ•°æ®é›†",
            "detail": "åŸºäºé«˜é€šé“ç”µæçš„ç¥ç»å…ƒæ”¾ç”µè®°å½•æ•°æ®",
            "rating": {
                "openness": 9,
                "quality": 9,
                "scale": 5,
                "impact": 2,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 5.35
            }
        },
{
            "name": "RSNA Intracranial Hemorrhage Detection",
            "desc": "RSNAé¢…å†…å‡ºè¡€æ£€æµ‹/åˆ†ç±»æ•°æ®é›†",
            "detail": "åŸºäºé«˜é€šé“ç”µæçš„ç¥ç»å…ƒæ”¾ç”µè®°å½•æ•°æ®",
            "rating": {
                "openness": 0,
                "quality": 0,
                "scale": 5,
                "impact": 6,
                "safety": 10,
                "ai_readiness": 4,
                "total_score": 4.3
            }
        },
{
            "name": "APT-36K",
            "desc": "ç”¨äºåŠ¨ç‰©å§¿æ€ä¼°è®¡ä¸è·Ÿè¸ªçš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†",
            "detail": "åŸºäºé«˜é€šé“ç”µæçš„ç¥ç»å…ƒæ”¾ç”µè®°å½•æ•°æ®",
            "rating": {
                "openness": 8,
                "quality": 9,
                "scale": 4,
                "impact": 2,
                "safety": 7,
                "ai_readiness": 9,
                "total_score": 5.55
            }
        }
    ],

    "ç”Ÿå‘½ç§‘å­¦": [
        {
            "name": "AlphaFold Protein Structure Database",
            "desc": "AlphaFoldæ•°æ®åº“",
            "detail": "å…¨çƒæœ€å¤§çš„æ ¸é…¸åºåˆ—å­˜å‚¨ä¸å…±äº«æ•°æ®åº“ä¹‹ä¸€",
            "rating": {
                "openness": 8,
                "quality": 10,
                "scale": 7,
                "impact": 6,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 6.95
            }
        },
        {
            "name": "STRING â€” Search Tool for the Retrieval of Interacting Genes/Proteins",
            "desc": "STRINGè›‹ç™½äº¤äº’ç½‘ç»œæ•°æ®åº“",
            "detail": "æä¾›é«˜è´¨é‡çš„è›‹ç™½è´¨åºåˆ—ã€åŠŸèƒ½ä¸ç»“æ„æ³¨é‡Šä¿¡æ¯",
            "rating": {
                "openness": 8,
                "quality": 9,
                "scale": 5,
                "impact": 8,
                "safety": 7,
                "ai_readiness": 5,
                "total_score": 6.55
        }
        },
        {
            "name": "Universal Protein Resource",
            "desc": "è›‹ç™½è´¨ç»Ÿä¸€èµ„æºåº“",
            "detail": "é€šè¿‡å•ç»†èƒæµ‹åºæŠ€æœ¯æ„å»ºäººä½“ç»†èƒå‚è€ƒå›¾è°±",
            "rating": {
                "openness": 8,
                "quality": 10,
                "scale": 4,
                "impact": 8,
                "safety": 7,
                "ai_readiness": 6,
                "total_score": 6.55
            }
        },
        {
            "name": "InterPro",
            "desc": "ç»¼åˆè›‹ç™½è´¨å®¶æ—ã€ç»“æ„åŸŸå’ŒåŠŸèƒ½ä½ç‚¹æ³¨é‡Šæ•°æ®åº“",
            "detail": "é€šè¿‡å•ç»†èƒæµ‹åºæŠ€æœ¯æ„å»ºäººä½“ç»†èƒå‚è€ƒå›¾è°±",
            "rating": {
                "openness": 0,
                "quality": 10,
                "scale": 6,
                "impact": 6,
                "safety": 7,
                "ai_readiness": 8,
                "total_score": 6.25
            }
        },
        {
            "name": "SPICE: Substituted, Polar, Intermolecular, Conformational, and Electronic dataset",
            "desc": "SPICEåˆ†å­åŠ›åœºæœºå™¨å­¦ä¹ æ•°æ®é›†",
            "detail": "é€šè¿‡å•ç»†èƒæµ‹åºæŠ€æœ¯æ„å»ºäººä½“ç»†èƒå‚è€ƒå›¾è°±",
            "rating": {
                "openness": 9,
                "quality": 9,
                "scale": 4,
                "impact": 6,
                "safety": 7,
                "ai_readiness": 8,
                "total_score": 6.45
            }
        },
    ],
}

# å¯åŠ¨æ—¶åŠ è½½ alias æ˜ å°„ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
with open("dataset_alias_map.json", encoding="utf-8") as f:
    ALIAS_MAP = json.load(f)

def resolve_dataset_id(input_id: str) -> str:
    """
    å°†å‰ç«¯ä¼ å…¥çš„ id / æœç´¢è¯ æ˜ å°„ä¸ºè§„èŒƒ dataset_id
    """
    if not input_id:
        return ""

    key = input_id.strip()

    # å…ˆå°è¯•ç›´æ¥æ˜ å°„
    if key in ALIAS_MAP:
        return ALIAS_MAP[key]

    # å†å°è¯•å¤§å°å†™ä¸æ•æ„Ÿ
    key_lower = key.lower()
    for alias, dataset_id in ALIAS_MAP.items():
        if alias.lower() == key_lower:
            return dataset_id

    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå…œåº•ï¼šåšä¸€æ¬¡ safe åŒ–
    return (
        key.replace(" ", "_")
           .replace("/", "_")
    )

# -------------------------
# è·å–å­¦ç§‘åˆ—è¡¨
# -------------------------
@app.get("/api/topics")
def get_topics():
    return list(DATASETS.keys())


# -------------------------
# è·å–æŸä¸ªå­¦ç§‘çš„æ•°æ®é›†
# -------------------------
@app.get("/api/datasets")
def get_datasets(topic: str):
    return DATASETS.get(topic, [])

@app.get("/dataset", response_class=HTMLResponse)
def dataset_page():
    return ("../dataset.html").read_text(encoding="utf-8")


# è·å–æ•°æ®é›†æ–‡ä»¶å†…å®¹
@app.get("/api/dataset-path")
def get_dataset_path(id: str):
    """
    æ ¹æ® dataset_id è¿”å›å¯¹åº”çš„æ•°æ®é›†å†…å®¹
    """
    # ğŸ”‘ æ–°å¢ï¼šid æ˜ å°„
    dataset_id = resolve_dataset_id(id)
    # å‡è®¾æ•°æ®é›†æ–‡ä»¶åæ˜¯ dataset_id_ratings.json
    safe_id = dataset_id.replace(" ", "_")
    dataset_path = os.path.join("groundtruth", f"{safe_id}_ratings1.json")
    print(f"dataset_path: {dataset_path}")
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(dataset_path):
        with open(dataset_path, "r", encoding="utf-8") as file:
            dataset_content = json.load(file)  # è§£æ JSON æ–‡ä»¶å†…å®¹
            print("æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return JSONResponse(content=dataset_content)  # è¿”å›æ–‡ä»¶å†…å®¹ä½œä¸º JSON
    else:
        print("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œç°åœºæœç´¢")
        # profile = asyncio.run(build_dataset_profile(
        #     dataset_name="Hubble Space Telescope Data",
        #     openai_api_key="sk-N2YmdRCjPQKKN01BoDjvrWW1yU8YwidaZQ9X0mkYI5QdqQRo",
        #     serper_api_key="809a347173275d7cfe4a5a6f4497ad3e38b45a0a",
        #     template_path="results/CMIP_ratings.json"  # æå‰å‡†å¤‡å­—æ®µç»“æ„
        # ))
        # return JSONResponse(content=profile)  # è¿”å›æ–‡ä»¶å†…å®¹ä½œä¸º JSON
        return JSONResponse(content={"error": "Dataset file not found"}, status_code=404)

# è·å–æ•°æ®é›†æ–‡ä»¶è¯„åˆ†
@app.get("/api/dataset-score")
def get_dataset_score(id: str):
    """
    æ ¹æ® dataset_id è¿”å›å¯¹åº”çš„æ•°æ®é›†å†…å®¹
    """
    # ğŸ”‘ æ–°å¢ï¼šid æ˜ å°„
    dataset_id = resolve_dataset_id(id)
    # å‡è®¾æ•°æ®é›†æ–‡ä»¶åæ˜¯ dataset_id_ratings.json
    safe_id = dataset_id.replace(" ", "_").replace("/", "_")
    dataset_path = os.path.join("scores", f"{safe_id}_scores.json")
    print(f"dataset_score_path: {dataset_path}")
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(dataset_path):
        with open(dataset_path, "r", encoding="utf-8") as file:
            dataset_content = json.load(file)  # è§£æ JSON æ–‡ä»¶å†…å®¹
            print("æ‰¾åˆ°è¯„åˆ†æ–‡ä»¶")
        return JSONResponse(content=dataset_content)  # è¿”å›æ–‡ä»¶å†…å®¹ä½œä¸º JSON
    else:
        print("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return JSONResponse(content={"error": "Dataset file not found"}, status_code=404)

# åˆ¤æ–­ç”¨æˆ·è¾“å…¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨
@app.get("/api/dataset-exists")
async def dataset_exists(query: str, type: str):
    """
    æ£€æŸ¥æœç´¢è¯æ˜¯å¦åœ¨ dataset_alias_map.json ä¸­
    """
    print("query:", query)
    if not query:
        return {"type": "unknown","exists": False}

    # catalog = analyze_input_catalog(query)
    # 1ï¸âƒ£ ç§‘å­¦æ•°æ®
    if type == "dataset":
        key = query.strip()
        key_lower = key.lower()
        for alias, dataset_id in ALIAS_MAP.items():
            if alias.lower() == key_lower:
                print("åœ¨æ˜ å°„æ–‡ä»¶ä¸­æ‰¾åˆ°æ•°æ®é›†")
                return {
                    "type": "dataset",
                    "exists": True,
                    "dataset_id": dataset_id
                }
        print("æ˜ å°„æ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼Œç°åœºæœç´¢")
        # search_logger.info("æ˜ å°„æ–‡ä»¶ä¸­ä¸å­˜åœ¨ï¼Œç°åœºæœç´¢")
        profile = await build_dataset_profile(
            dataset_name=query,
            openai_api_key="sk-N2YmdRCjPQKKN01BoDjvrWW1yU8YwidaZQ9X0mkYI5QdqQRo",
            serper_api_key="809a347173275d7cfe4a5a6f4497ad3e38b45a0a",
            template_path="groundtruth/AirfRANS_ratings.json"  # æå‰å‡†å¤‡å­—æ®µç»“æ„
        )
        print(json.dumps(profile, indent=2, ensure_ascii=False))
        return {
            "type": "dataset",
            "exists": True,
            "dataset_id": query
        }
    # 2ï¸âƒ£ ç§‘å­¦é—®é¢˜
    elif type == "task":
        return {
            "type": "text",
            "exists": True
        }

    return {"type": "dataset","exists": False}

# -------------------------
# ğŸ” æœç´¢ä¸ç§‘å­¦é—®é¢˜ç›¸å…³çš„æ•°æ®é›†
# -------------------------
@app.get("/api/question_analysis")
def question_analysis(query: str):
    return analyze_user_input(query)

@app.get("/api/search_question_datasets")
def search_question_datasets(query: str):
    # time.sleep(3)
    print("query:", query)
    emb1 = model.encode([query])
    excel_path = "/Users/liuxiang/Desktop/scidata.xlsx"
    df = pd.read_excel(excel_path) if excel_path.endswith("xlsx") else pd.read_csv(excel_path)
    results = []
    for _, row in df.iterrows():
        dataset_name = row["æ•°æ®åç§°"]  # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ•°æ®é›†åç§°
        file_name = f"{dataset_name.replace(' ', '_').replace('/', '-')}_ratings1.json"
        with open(f"groundtruth/{file_name}", "r", encoding="utf-8") as f:
            data = json.load(f)
            # print(data["intro"]["detailed_description"])
            # print("\n")
            emb2 = model.encode([data["intro"]["detailed_description"]])
        # sim = cosine_similarity(emb1, emb2)[0][0]
        sim = similarity_retrival(query, data["intro"]["detailed_description"])
        print(file_name, sim)  # 0.7+ å°±å¾ˆåƒ
        results.append({
            "dataset_name": dataset_name,
            "similarity": float(sim)
        })
    # 6ï¸âƒ£ æŒ‰ç›¸ä¼¼åº¦æ’åº & å– top-k
    scores = []
    results = sorted(results, key=lambda x: x["similarity"], reverse=True)
    for result in results[:3]:
        print(result["dataset_name"])
        score_file = f"{result["dataset_name"].replace(' ', '_').replace('/', '-')}_scores.json"
        with open(f"scores/{score_file}", "r", encoding="utf-8") as f:
            score = json.load(f)
            scores.append(score)
            print(score)
    print("æœç´¢ä¸ç§‘å­¦é—®é¢˜ç›¸å…³çš„æ•°æ®é›†")
    return {"datasets": scores}
    # return  {
    #     "datasets": [
    #         {
    #             "name": "ERA5",
    #             "desc": "Global atmospheric reanalysis dataset providing hourly atmospheric variables",
    #             "rating": {
    #                 "openness": 5,
    #                 "scale": 5,
    #                 "impact": 5,
    #                 "safety": 5,
    #                 "ai_readiness": 4,
    #                 "quality": 5,
    #                 "total_score": 4.9
    #             }
    #         },
    #         {
    #             "name": "CMIP6",
    #             "desc": "Coupled Model Intercomparison Project Phase 6 climate model outputs",
    #             "rating": {
    #                 "openness": 4,
    #                 "scale": 5,
    #                 "impact": 5,
    #                 "safety": 4,
    #                 "ai_readiness": 3,
    #                 "quality": 4,
    #                 "total_score": 4.3
    #             }
    #         },
    #         {
    #             "name": "Landsat 8",
    #             "desc": "Multispectral satellite imagery for Earth observation",
    #             "rating": {
    #                 "openness": 5,
    #                 "scale": 4,
    #                 "impact": 4,
    #                 "safety": 5,
    #                 "ai_readiness": 4,
    #                 "quality": 4,
    #                 "total_score": 4.2
    #             }
    #         }
    #     ]
    #
    # }

# -------------------------
# ğŸ” æœç´¢æ¥å£ï¼ˆä½ çœŸæ­£å…³å¿ƒçš„ï¼‰
# -------------------------
@app.get("/api/search")
def search_datasets(
    query: str = Query(..., description="æœç´¢å…³é”®è¯"),
    topic: str | None = None,
):
    """
    ğŸ”¥ ä½ ä»¥ååªéœ€è¦æ”¹è¿™ä¸ªå‡½æ•°é‡Œçš„é€»è¾‘
    """
    results = []

    for t, datasets in DATASETS.items():
        if topic and t != topic:
            continue
        for ds in datasets:
            if query.lower() in ds["name"].lower():
                results.append(ds)

    return results
